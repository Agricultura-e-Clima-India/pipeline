{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb199e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caminho '..' foi adicionado: c:\\Users\\luizz\\Downloads\\Entrega Pipeline Final\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "print(f\"Caminho '..' foi adicionado: {os.path.abspath('..')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando script de carregamento da camada GOLD para o Data Warehouse...\n",
      "Conexão com o banco de dados estabelecida.\n",
      "Encontrados 7 arquivos CSV para carregar.\n",
      "\n",
      "Iniciando carregamento de 'analise_sazonal_clima.csv' para a tabela 'analise_sazonal_clima'...\n",
      " -> Sucesso! Dados de 'analise_sazonal_clima.csv' carregados na tabela 'analise_sazonal_clima'.\n",
      "\n",
      "Iniciando carregamento de 'benchmark_regional_rendimento.csv' para a tabela 'benchmark_regional_rendimento'...\n",
      " -> Sucesso! Dados de 'benchmark_regional_rendimento.csv' carregados na tabela 'benchmark_regional_rendimento'.\n",
      "\n",
      "Iniciando carregamento de 'desempenho_regiao_cultura.csv' para a tabela 'desempenho_regiao_cultura'...\n",
      " -> Sucesso! Dados de 'desempenho_regiao_cultura.csv' carregados na tabela 'desempenho_regiao_cultura'.\n",
      "\n",
      "Iniciando carregamento de 'perfil_climatico_regiao_cultura.csv' para a tabela 'perfil_climatico_regiao_cultura'...\n",
      " -> Sucesso! Dados de 'perfil_climatico_regiao_cultura.csv' carregados na tabela 'perfil_climatico_regiao_cultura'.\n",
      "\n",
      "Iniciando carregamento de 'producao_anual_cultura.csv' para a tabela 'producao_anual_cultura'...\n",
      " -> Sucesso! Dados de 'producao_anual_cultura.csv' carregados na tabela 'producao_anual_cultura'.\n",
      "\n",
      "Iniciando carregamento de 'tendencia_anual_rendimento.csv' para a tabela 'tendencia_anual_rendimento'...\n",
      " -> Sucesso! Dados de 'tendencia_anual_rendimento.csv' carregados na tabela 'tendencia_anual_rendimento'.\n",
      "\n",
      "Iniciando carregamento de 'volatilidade_rendimento_regiao.csv' para a tabela 'volatilidade_rendimento_regiao'...\n",
      " -> Sucesso! Dados de 'volatilidade_rendimento_regiao.csv' carregados na tabela 'volatilidade_rendimento_regiao'.\n",
      "\n",
      "--- Resumo do Carregamento ---\n",
      "Arquivos carregados com sucesso: 7\n",
      "Todos os arquivos foram processados sem falhas.\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from database.config.database import get_connection_string\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- Configuração ---\n",
    "# Define o caminho para a pasta gold\n",
    "GOLD_DATA_DIR = \"../data/gold/\"\n",
    "FILE_PATTERN = \"*.csv\"\n",
    "full_path_pattern = os.path.join(GOLD_DATA_DIR, FILE_PATTERN)\n",
    "\n",
    "# --- Contadores para resumo ---\n",
    "files_loaded_count = 0\n",
    "files_failed = []\n",
    "\n",
    "print(\"Iniciando script de carregamento da camada GOLD para o Data Warehouse...\")\n",
    "\n",
    "try:\n",
    "    # 1. Obter a string de conexão\n",
    "    db_url = get_connection_string()\n",
    "\n",
    "    # 2. Criar o engine do SQLAlchemy\n",
    "    engine = create_engine(db_url)\n",
    "    print(\"Conexão com o banco de dados estabelecida.\")\n",
    "\n",
    "    # 3. Encontrar todos os arquivos CSV na pasta gold\n",
    "    csv_files = glob.glob(full_path_pattern)\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"Aviso: Nenhum arquivo .csv encontrado em '{full_path_pattern}'\")\n",
    "    else:\n",
    "        print(f\"Encontrados {len(csv_files)} arquivos CSV para carregar.\")\n",
    "\n",
    "    # 4. Iterar sobre cada arquivo CSV encontrado\n",
    "    for file_path in csv_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        try:\n",
    "            # Extrair o nome da tabela do nome do arquivo\n",
    "            # (ex: ../data/gold/minha_tabela.csv -> minha_tabela)\n",
    "            table_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "            print(f\"\\nIniciando carregamento de '{file_name}' para a tabela '{table_name}'...\")\n",
    "\n",
    "            # Ler o CSV para um DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\" -> Aviso: O arquivo '{file_name}' está vazio. Pulando.\")\n",
    "                continue\n",
    "\n",
    "            # Salvar no PostgreSQL usando pandas\n",
    "            # 'if_exists=\"replace\"' garante que a tabela seja recriada a cada execução\n",
    "            df.to_sql(\n",
    "                name=table_name,\n",
    "                con=engine,\n",
    "                if_exists=\"replace\",\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "            print(f\" -> Sucesso! Dados de '{file_name}' carregados na tabela '{table_name}'.\")\n",
    "            files_loaded_count += 1\n",
    "\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\" -> Erro: O arquivo '{file_name}' está vazio e não pôde ser lido. Pulando.\")\n",
    "            files_failed.append(file_name)\n",
    "        except Exception as e_file:\n",
    "            print(f\" -> Erro ao processar o arquivo '{file_name}': {e_file}\")\n",
    "            files_failed.append(file_name)\n",
    "\n",
    "    # 5. Imprimir resumo final\n",
    "    print(\"\\n--- Resumo do Carregamento ---\")\n",
    "    print(f\"Arquivos carregados com sucesso: {files_loaded_count}\")\n",
    "    if files_failed:\n",
    "        print(f\"Arquivos que falharam: {len(files_failed)}\")\n",
    "        for f_name in files_failed:\n",
    "            print(f\"  - {f_name}\")\n",
    "    else:\n",
    "        print(\"Todos os arquivos foram processados sem falhas.\")\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Erro: SQLAlchemy não está instalado. Por favor, instale com 'pip install sqlalchemy psycopg2-binary'\")\n",
    "except Exception as e_global:\n",
    "    print(f\"Ocorreu um erro crítico durante a execução: {e_global}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
