{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6790b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eeb89a",
   "metadata": {},
   "source": [
    "--- Execução do Notebook Silver ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abadc5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo Bronze\n",
    "bronze_file_path = '../data/bronze/dados_brutos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76db3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados originais carregados: (325753, 31)\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados da camada Bronze\n",
    "try:\n",
    "    if not os.path.exists(bronze_file_path):\n",
    "        print(f\"Erro: Arquivo '{bronze_file_path}' não encontrado.\")\n",
    "        df_silver = pd.DataFrame()\n",
    "    else:\n",
    "        df_silver = pd.read_csv(bronze_file_path)\n",
    "        print(f\"Dados originais carregados: {df_silver.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao carregar o arquivo '{bronze_file_path}': {e}\")\n",
    "    df_silver = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63a03a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes de colunas padronizados.\n",
      "Duplicatas removidas: 0\n",
      "Tratamento de nulos concluído.\n",
      "Colunas de texto padronizadas (strip/upper).\n",
      "Removida 0 linha(s) de 'header como dado'.\n",
      "Coluna 'state_district' criada com sucesso.\n",
      "Colunas 'state' e 'district' removidas.\n",
      "Dados filtrados para as colheitas desejadas. Novo shape: (56086, 30)\n",
      "\n",
      "Removendo registros com 'area' ou 'yield' zerados...\n",
      "Linhas removidas pelos filtros de zero: 404\n",
      "Linhas restantes após o filtro de zeros: 55682\n",
      "\n",
      "=== VALIDAÇÕES DE QUALIDADE ===\n",
      "Completude: 100.00%\n",
      "Unicidade: 100.00% (Total de 0 duplicatas restantes)\n",
      "\n",
      "Dados limpos salvos: (55682, 31)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def standardize_columns(df):\n",
    "    \"\"\"\n",
    "    Padroniza os nomes das colunas de um DataFrame:\n",
    "    - Converte para minúsculas.\n",
    "    - Substitui espaços e caracteres não alfanuméricos por underscore.\n",
    "    - Remove múltiplos underscores e no início/fim.\n",
    "    \"\"\"\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        new_col = col.lower()\n",
    "        new_col = re.sub(r'[\\s\\.\\-\\/]+', '_', new_col)\n",
    "        new_col = re.sub(r'[^a-z0-9_]', '', new_col)\n",
    "        new_col = re.sub(r'_+', '_', new_col)\n",
    "        new_col = new_col.strip('_')\n",
    "        new_columns.append(new_col)\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "# Verificar se o DataFrame não está vazio antes de prosseguir com as transformações\n",
    "if not df_silver.empty:\n",
    "    # ==========================================\n",
    "    # ETAPA 0: Padronizar Nomes de Colunas\n",
    "    # ==========================================\n",
    "    df_silver = standardize_columns(df_silver.copy())\n",
    "    print(\"Nomes de colunas padronizados.\")\n",
    "\n",
    "    # ==========================================\n",
    "    # TRANSFORMAÇÃO 1: Remover Duplicatas\n",
    "    # ==========================================\n",
    "    linhas_antes = len(df_silver)\n",
    "    df_silver = df_silver.drop_duplicates().copy()\n",
    "    linhas_depois = len(df_silver)\n",
    "    print(f\"Duplicatas removidas: {linhas_antes - linhas_depois}\")\n",
    "\n",
    "    # ==========================================\n",
    "    # TRANSFORMAÇÃO 2: Tratar Valores Nulos\n",
    "    # ==========================================\n",
    "    colunas_regiao = ['state', 'district']\n",
    "    df_silver = df_silver.dropna(subset=colunas_regiao).copy()\n",
    "\n",
    "    # Preencher valores numéricos com a mediana\n",
    "    colunas_numericas = df_silver.select_dtypes(include=[np.number]).columns\n",
    "    df_silver[colunas_numericas] = df_silver[colunas_numericas].fillna(df_silver[colunas_numericas].median())\n",
    "\n",
    "    # Preencher valores categóricos restantes com 'Desconhecido'\n",
    "    colunas_texto = df_silver.select_dtypes(include=['object']).columns\n",
    "    df_silver[colunas_texto] = df_silver[colunas_texto].fillna('Desconhecido')\n",
    "    print(\"Tratamento de nulos concluído.\")\n",
    "\n",
    "    # ==========================================\n",
    "    # TRANSFORMAÇÃO 3: Padronizar Valores e Criar Coluna-Chave\n",
    "    # ==========================================\n",
    "    # 1. Padronizar colunas de texto (strip/upper)\n",
    "    colunas_para_padronizar = ['state', 'district', 'crop', 'season']\n",
    "    for coluna in colunas_para_padronizar:\n",
    "        if coluna in df_silver.columns:\n",
    "            df_silver[coluna] = df_silver[coluna].astype(str).str.strip().str.upper().copy()\n",
    "    print(\"Colunas de texto padronizadas (strip/upper).\")\n",
    "\n",
    "    # Filtra linhas onde a coluna 'state' (agora em maiúsculo) tem o valor literal 'STATE'.\n",
    "    linhas_antes_filtro_header = len(df_silver)\n",
    "    df_silver = df_silver[df_silver['state'] != 'STATE'].copy()\n",
    "    print(f\"Removida {linhas_antes_filtro_header - len(df_silver)} linha(s) de 'header como dado'.\")\n",
    "\n",
    "    # 3. Criar a coluna combinada 'state_district'\n",
    "    if 'state' in df_silver.columns and 'district' in df_silver.columns:\n",
    "        df_silver['state_district'] = (df_silver['state'] + ' - ' + df_silver['district']).copy()\n",
    "        print(\"Coluna 'state_district' criada com sucesso.\")\n",
    "\n",
    "    # Remover colunas state e district\n",
    "    df_silver.drop(columns=['state', 'district'], inplace=True)\n",
    "    print(\"Colunas 'state' e 'district' removidas.\")\n",
    "\n",
    "    # ==========================================\n",
    "    # TRANSFORMAÇÃO 4: Simplificar o escopo de colheita/Crop (Filtro)\n",
    "    # ==========================================\n",
    "    valores_desejados = ['MAIZE','RICE','WHEAT','BARLEY']\n",
    "    if 'crop' in df_silver.columns:\n",
    "        mascara = df_silver['crop'].isin(valores_desejados)\n",
    "        df_silver = df_silver[mascara].copy()\n",
    "        print(f\"Dados filtrados para as colheitas desejadas. Novo shape: {df_silver.shape}\")\n",
    "    else:\n",
    "        print(\"Aviso: A coluna 'crop' não foi encontrada. A Transformação 4 foi ignorada.\")\n",
    "\n",
    "    # ==========================================\n",
    "    # TRANSFORMAÇÃO 5: Remover Registros de Produção Zero\n",
    "    # ==========================================\n",
    "    print(f\"\\nRemovendo registros com 'area' ou 'yield' zerados...\")\n",
    "    linhas_antes_filtro_zero = len(df_silver)\n",
    "\n",
    "    # Filtro 1: Remove registros onde a área plantada é 0\n",
    "    if 'area' in df_silver.columns:\n",
    "        df_silver = df_silver[df_silver['area'] > 0].copy()\n",
    "\n",
    "    # Filtro 2: Remove registros onde o rendimento é 0\n",
    "    if 'yield' in df_silver.columns:\n",
    "        df_silver = df_silver[df_silver['yield'] > 0].copy()\n",
    "\n",
    "    linhas_depois_filtro_zero = len(df_silver)\n",
    "    print(f\"Linhas removidas pelos filtros de zero: {linhas_antes_filtro_zero - linhas_depois_filtro_zero}\")\n",
    "    print(f\"Linhas restantes após o filtro de zeros: {len(df_silver)}\")\n",
    "\n",
    "\n",
    "    # ==========================================\n",
    "    # VALIDAÇÕES BÁSICAS (Para fins de log)\n",
    "    # ==========================================\n",
    "    print(\"\\n=== VALIDAÇÕES DE QUALIDADE ===\")\n",
    "    if not df_silver.empty:\n",
    "        total_celulas = df_silver.shape[0] * df_silver.shape[1]\n",
    "        celulas_preenchidas = df_silver.count().sum()\n",
    "        completude = (celulas_preenchidas / total_celulas) * 100\n",
    "        print(f\"Completude: {completude:.2f}%\")\n",
    "\n",
    "        duplicatas = df_silver.duplicated().sum()\n",
    "        unicidade = ((len(df_silver) - duplicatas) / len(df_silver)) * 100\n",
    "        print(f\"Unicidade: {unicidade:.2f}% (Total de {duplicatas} duplicatas restantes)\")\n",
    "    else:\n",
    "        print(\"Validação ignorada: DataFrame está vazio após as transformações.\")\n",
    "\n",
    "    # Adicionar informações de processamento\n",
    "    df_silver['data_processamento'] = datetime.now()\n",
    "\n",
    "    # Salvar na camada Silver\n",
    "    silver_file_path = '../data/silver/dados_limpos.csv'\n",
    "    os.makedirs(os.path.dirname(silver_file_path), exist_ok=True)\n",
    "    df_silver.to_csv(silver_file_path, index=False)\n",
    "    print(f\"\\nDados limpos salvos: {df_silver.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56bfc216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         crop  year  season     area  production  yield   jan   feb   mar  \\\n",
      "355     MAIZE  2007    RABI   230.81       879.0   3.81   1.7  36.7  35.2   \n",
      "356     MAIZE  2008  SUMMER   239.00       641.0   2.68  18.4  19.3  41.2   \n",
      "357     MAIZE  2009  SUMMER   163.00       405.0   2.48  12.0  12.0  14.2   \n",
      "358     MAIZE  2010    RABI     3.84        18.0   4.74   7.5  17.0  14.0   \n",
      "359     MAIZE  2011    RABI     4.00         3.0   0.68   6.8  25.8  22.4   \n",
      "...       ...   ...     ...      ...         ...    ...   ...   ...   ...   \n",
      "325748  WHEAT  2014    RABI  1622.00      3663.0   2.26  19.2  27.4  36.1   \n",
      "325749  WHEAT  2015    RABI   855.00      1241.0   1.45  17.9  25.6  36.1   \n",
      "325750  WHEAT  2016    RABI  1366.00      2415.0   1.77  17.6  26.2  34.4   \n",
      "325751  WHEAT  2017    RABI  1052.00      2145.0   2.04  18.2  26.6  33.0   \n",
      "325752  WHEAT  2018    RABI   833.00      2114.0   2.54  18.5  26.5  32.1   \n",
      "\n",
      "         apr  ...  jun_sep  oct_dec  temp_annual  temp_jan_feb  temp_mar_may  \\\n",
      "355     30.6  ...    943.0     85.4        24.77         20.10         26.69   \n",
      "356     29.5  ...    877.8     88.1        24.61         19.16         26.46   \n",
      "357     25.1  ...    698.3    136.1        25.11         20.72         26.86   \n",
      "358     39.0  ...    911.1    153.2        25.13         20.19         27.83   \n",
      "359     41.1  ...    901.3     65.8        24.67         19.54         26.38   \n",
      "...      ...  ...      ...      ...          ...           ...           ...   \n",
      "325748  22.2  ...    782.1     85.3        24.73         19.58         26.24   \n",
      "325749  42.1  ...    878.5    121.6        24.91         20.12         26.29   \n",
      "325750  42.8  ...    886.6    125.0        25.15         22.25         28.86   \n",
      "325751  41.5  ...    897.7    126.0        24.79         21.84         28.41   \n",
      "325752  39.5  ...    889.8    126.8        25.09         21.24         28.16   \n",
      "\n",
      "        temp_jun_sep  temp_oct_dec               data_ingestao  \\\n",
      "355            27.49         22.32  2025-11-23 16:47:51.538121   \n",
      "356            27.26         22.87  2025-11-23 16:47:51.538121   \n",
      "357            27.89         22.58  2025-11-23 16:47:51.538121   \n",
      "358            27.50         22.60  2025-11-23 16:47:51.538121   \n",
      "359            27.54         22.71  2025-11-23 16:47:51.538121   \n",
      "...              ...           ...                         ...   \n",
      "325748         27.88         22.47  2025-11-23 16:47:51.538121   \n",
      "325749         27.73         22.99  2025-11-23 16:47:51.538121   \n",
      "325750         28.44         24.20  2025-11-23 16:47:51.538121   \n",
      "325751         28.50         24.21  2025-11-23 16:47:51.538121   \n",
      "325752         28.28         23.55  2025-11-23 16:47:51.538121   \n",
      "\n",
      "                               state_district         data_processamento  \n",
      "355     ANDAMAN AND NICOBAR ISLAND - NICOBARS 2025-11-23 16:48:48.557959  \n",
      "356     ANDAMAN AND NICOBAR ISLAND - NICOBARS 2025-11-23 16:48:48.557959  \n",
      "357     ANDAMAN AND NICOBAR ISLAND - NICOBARS 2025-11-23 16:48:48.557959  \n",
      "358     ANDAMAN AND NICOBAR ISLAND - NICOBARS 2025-11-23 16:48:48.557959  \n",
      "359     ANDAMAN AND NICOBAR ISLAND - NICOBARS 2025-11-23 16:48:48.557959  \n",
      "...                                       ...                        ...  \n",
      "325748                  WEST BENGAL - PURULIA 2025-11-23 16:48:48.557959  \n",
      "325749                  WEST BENGAL - PURULIA 2025-11-23 16:48:48.557959  \n",
      "325750                  WEST BENGAL - PURULIA 2025-11-23 16:48:48.557959  \n",
      "325751                  WEST BENGAL - PURULIA 2025-11-23 16:48:48.557959  \n",
      "325752                  WEST BENGAL - PURULIA 2025-11-23 16:48:48.557959  \n",
      "\n",
      "[55682 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_silver)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
